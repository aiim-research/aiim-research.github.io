<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Artificial Intelligence and Information Mining - Collective: Unraveling Graph Counterfactual Explainability: from Theoretical Foundations to Technical Mastery</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta http-equiv="Permissions-Policy" content="interest-cohort=()">
        <!-- bootstrap -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
        <!-- fontawesome -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <script src="https://kit.fontawesome.com/be7d5ac8d8.js" crossorigin="anonymous"></script>
        <!-- favicon -->
        <link rel="apple-touch-icon" sizes="180x180" href="/img/fav/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/img/fav/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/img/fav/favicon-16x16.png">
        <link rel="manifest" href="/site.webmanifest">  
        <!-- our custom css -->
        <link rel="stylesheet" href="/css/group.css">
        <!-- site.canonical enabled -->
        <link rel="canonical" href="https://aiimlab.org/events/ECML_PKDD_2025_Unraveling_Graph_Counterfactual_Explainability_from_Theoretical_Foundations_to_Technical_Mastery" /> 
        
    </head>
     <!-- Google tag (gtag.js) -->
     <script async src="https://www.googletagmanager.com/gtag/js?id=G-HRVN2FKZRV"></script>
     <script>
         window.dataLayer = window.dataLayer || [];
         function gtag(){dataLayer.push(arguments);}
         gtag('js', new Date());

         gtag('config', 'G-HRVN2FKZRV');
     </script>
    <body>
        <div class="container">
            <!-- This is a bit nasty, but it basically says be a column first, and on larger screens be a spaced out row -->
            <div class="sticky-top header d-flex 
                        flex-column
                        flex-md-row justify-content-md-between">
                <a href="/" class="">
                    <img src="/img/AIIM-Logo.svg"
                         srcset="/img/AIIM-Logo.svg 2x"
                         alt="AIIM - Artificial Intelligence and Information Mining research group." id="logo">
                </a>
                <ul class="nav nav-pills justify-content-center">

                    
                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/">
                                Home
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/news.html">
                                News
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/blogs.html">
                                Researches
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/research.html">
                                Projects
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link active"
                               href="/events.html">
                                Events
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/code.html">
                                Resources
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/people.html">
                                People
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/publications.html">
                                Publications
                            </a>
                        </li>

                    

                </ul>
            </div>

            
                
                <a href="https://ecmlpkdd.org/" class="">
                
                <img src="https://ecmlpkdd-storage.s3.eu-central-1.amazonaws.com/ECML_1_e012008d41.png"
                     alt="Unraveling Graph Counterfactual Explainability: from Theoretical Foundations to Technical Mastery"
                     style="max-width: 400px"
                     class="img-fluid mx-auto d-block mb-4"/>
                
                </a>
                
            

            
                <h2 class="pt-3">Unraveling Graph Counterfactual Explainability: from Theoretical Foundations to Technical Mastery</h2>
            
            
                <h3 class="pt-3">Tutorial at the the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD 2025)</h3>
            

            <br>
<h3> Organisers </h3>
<section class="people project-people">
    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://bardhprenkaj.netlify.app/"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Dr. Bardh Prenkaj"
             title="Dr. Bardh Prenkaj"
             src="/img/people/prenkaj.jpeg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://bardhprenkaj.netlify.app/"> Dr. Bardh Prenkaj </a>
     </h6>
            
                <div class="bio">Technical University of Munich</div>
            
        </div>
    </div>


    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://dangeloandrea14.github.io/"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Andrea D'Angelo"
             title="Andrea D'Angelo"
             src="/img/people/adangelo.png" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://dangeloandrea14.github.io/"> Andrea D'Angelo </a>
     </h6>
            
                <div class="bio">University of L'Aquila</div>
            
        </div>
    </div>


    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://www.gov.sot.tum.de/rds/team/stratis-zaradoukas/"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Efstratios Zaradoukas"
             title="Efstratios Zaradoukas"
             src="/img/people/events/ecmlpkdd_tutorial/stratis.jpg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://www.gov.sot.tum.de/rds/team/stratis-zaradoukas/"> Efstratios Zaradoukas </a>
     </h6>
            
                <div class="bio">Technical University of Munich</div>
            
        </div>
    </div>


    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://scholar.google.es/citations?hl=en&amp;user=NPie5kEAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Mario A. Prado-Romero"
             title="Mario A. Prado-Romero"
             src="/img/people/mprado.jpeg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://scholar.google.es/citations?hl=en&amp;user=NPie5kEAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"> Mario A. Prado-Romero </a>
     </h6>
            
                <div class="bio">Ph.D. 2025 at GSSI</div>
            
        </div>
    </div>


    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://scholar.google.com/citations?hl=en&amp;user=uTyaicMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Prof. Giovanni Stilo"
             title="Prof. Giovanni Stilo"
             src="/img/people/Stilo.jpeg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://scholar.google.com/citations?hl=en&amp;user=uTyaicMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"> Prof. Giovanni Stilo </a>
     </h6>
            
                <div class="bio">University of L'Aquila</div>
            
        </div>
    </div>


    
</section>
<!--<div class="highlight" height="500px"> 
        <embed
            src="/pdf/AAAI_2024_Graphs_Counterfactual_Explainability_A_Comprehensive_Landscape_SLIDES.pdf"
            type="application/pdf"
            width="100%"
            height="500px"
        />
</div>
<br>-->

<p class="text-justify">Slides can be downloaded <a href="#">TBA</a></p>
<p><br /></p>

<h3 class="pt-3">Table of contents</h3>
<ul>
  <li><a href="#Abstract">Abstract</a></li>
  <li><a href="#Duration">Duration</a></li>
  <li><a href="#Scope">Scope of the tutorial</a></li>
  <li><a href="#Prerequisites">Prerequisites</a></li>
  <li><a href="#Outline">Outline &amp; Contents</a></li>
  <li><a href="#Acknowledgement">Acknowledgement</a></li>
  <li><a href="#Speakers">Meet the Speakers</a></li>
  <li><a href="#Bibliography">Bibliography</a></li>
</ul>

<h3 class="pt-3">Highlights</h3>
<p>The tutorial is based on ACM Computing Survey: <a href="https://dl.acm.org/doi/abs/10.1145/3618105">A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation, and Research Challenges</a>
Use the following BibTeX to cite our paper.</p>

<figure class="highlight"><pre><code class="language-cpp" data-lang="cpp"><span class="err">@</span><span class="n">article</span><span class="p">{</span><span class="mf">10.1145</span><span class="o">/</span><span class="mi">3618105</span><span class="p">,</span>
    <span class="n">author</span> <span class="o">=</span> <span class="p">{</span><span class="n">Prado</span><span class="o">-</span><span class="n">Romero</span><span class="p">,</span> <span class="n">Mario</span> <span class="n">Alfonso</span> <span class="n">and</span> <span class="n">Prenkaj</span><span class="p">,</span> <span class="n">Bardh</span> <span class="n">and</span> <span class="n">Stilo</span><span class="p">,</span> <span class="n">Giovanni</span> <span class="n">and</span> <span class="n">Giannotti</span><span class="p">,</span> <span class="n">Fosca</span><span class="p">},</span>
    <span class="n">title</span> <span class="o">=</span> <span class="p">{</span><span class="n">A</span> <span class="n">Survey</span> <span class="n">on</span> <span class="n">Graph</span> <span class="n">Counterfactual</span> <span class="n">Explanations</span><span class="o">:</span> <span class="n">Definitions</span><span class="p">,</span> <span class="n">Methods</span><span class="p">,</span> <span class="n">Evaluation</span><span class="p">,</span> <span class="n">and</span> <span class="n">Research</span> <span class="n">Challenges</span><span class="p">},</span>
    <span class="n">year</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2023</span><span class="p">},</span>
    <span class="n">publisher</span> <span class="o">=</span> <span class="p">{</span><span class="n">Association</span> <span class="k">for</span> <span class="n">Computing</span> <span class="n">Machinery</span><span class="p">},</span>
    <span class="n">address</span> <span class="o">=</span> <span class="p">{</span><span class="n">New</span> <span class="n">York</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="n">USA</span><span class="p">},</span>
    <span class="n">issn</span> <span class="o">=</span> <span class="p">{</span><span class="mo">0360</span><span class="o">-</span><span class="mo">0300</span><span class="p">},</span>
    <span class="n">url</span> <span class="o">=</span> <span class="p">{</span><span class="n">https</span><span class="o">:</span><span class="c1">//doi.org/10.1145/3618105},</span>
    <span class="n">doi</span> <span class="o">=</span> <span class="p">{</span><span class="mf">10.1145</span><span class="o">/</span><span class="mi">3618105</span><span class="p">},</span>
    <span class="n">journal</span> <span class="o">=</span> <span class="p">{</span><span class="n">ACM</span> <span class="n">Computing</span> <span class="n">Surveys</span><span class="p">},</span>
    <span class="n">month</span> <span class="o">=</span> <span class="p">{</span><span class="n">sep</span><span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<h3 class="pt-3" id="Abstract">Abstract</h3>
<p>Graph Neural Networks (GNNs) are transforming AI applications in bioinformatics, fraud detection, recommender systems, and social network analysis. However, their black-box nature limits adoption in high-stakes domains where transparency is essential. Graph Counterfactual Explainability (GCE) addresses this challenge by identifying minimal changes in graph structure or features that alter model predictions, providing interpretable and actionable insights. This tutorial equips attendees with the theoretical foundations and practical tools to understand, develop, and apply counterfactual explainability methods for GNNs. We begin with an overview of GNN architectures and the challenges of generating post-hoc explanations. Next, we define GCE, exploring its advantages over factual explanations and its role in algorithmic recourse. We present a structured taxonomy of counterfactual explainers, covering search-based, heuristic, and learning-based approaches. Additionally, we examine evaluation metrics, datasets, and benchmarking protocols to assess the effectiveness of counterfactual explanations. A key focus is counterfactual explainability in evolving graphs, where distribution shifts and temporal dependencies affect model reliability. We also highlight the importance of open-source frameworks such as GRETEL, which provide standardized tools for evaluating and deploying counterfactual explainers, accelerating research and real-world adoption. By the end of this tutorial, participants will be equipped to critically assess counterfactual explanations, leverage existing frameworks, and apply GCE techniques in dynamic graph settings.
<br /></p>

<h3 class="pt-3" id="Duration">Duration</h3>
<p>The tutorial will be carried on for a half-day, spanning 4 hours, as the most suitable format to introduce attendees to counterfactual explanations on graphs and their foundational concepts. This duration strikes a balance between providing a comprehensive understanding of the topic and technical details to bootstrap their programming skills with GRETEL.
<br /></p>

<h3 class="pt-3" id="Scope">Scope of the tutorial</h3>
<p>The ECML-PKDD community has shown growing interest in Explainable AI and Graph Neural Networks (GNNs). Graph Counterfactual Explainability (GCE) offers a compelling direction by revealing minimal changes in graph structure or features that flip model predictions—providing actionable, human-interpretable insights into black-box GNNs. This tutorial will introduce the foundations of GNNs and explainability methods, before diving into counterfactual reasoning, its advantages over factual explanations, and its role in algorithmic recourse. We will present a structured taxonomy of GCE techniques, cover evaluation metrics and benchmarking protocols, and explore real-world applications on molecular and dynamic graphs. Special attention will be given to evolving graphs and open-source tools like GRETEL, which standardize and accelerate the development of GCE methods.</p>

<p>The tutorial is aimed at researchers and practitioners in machine learning, data mining, and XAI. Participants will gain both conceptual understanding and practical tools to develop and evaluate counterfactual explanations in graph-based models.
<br /></p>

<h3 class="pt-3" id="Prerequisites">Prerequisites</h3>
<p>The tutorial is aimed at practitioners in academia and industry interested in applying machine learning techniques to analyze graph data. 
Familiarity with basic ML concepts will be beneficial for thoroughly understanding the tutorial.
<br /></p>

<h3 class="pt-3" id="Outline">Outline &amp; Contents</h3>
<p>Counterfactual explanations shed light on the decision-making mechanisms and provide alternative scenarios that yield different outcomes, offering end users recourse—these distinctive characteristics position counterfactual explainability as a highly effective method in graph-based contexts. 
We adopt a multifaceted approach, organizing and examining GCE from different perspectives, such as method taxonomy, classification along various dimensions, detailed descriptions of individual works (including their evaluation processes), discussions on evaluation measures, and commonly used benchmark datasets.
We provide a brief outline of the tutorial in Figure 1. Here, we comprehensively review counterfactual explainability in graphs and their importance with other (factual) explainability methods.</p>

<div class="notes">
  <ul>
    <li><strong>Part I: Introduction and Background</strong> (20 mins)
      <ul>
        <li>The rise of Graph Neural Networks (GNNs) in AI</li>
        <li>Fundamental principles: How do GNNs work?</li>
        <li>Applications across domains:
          <ul>
            <li>Traffic Modeling</li>
            <li>Physical simulations</li>
            <li>Protein interaction networks</li>
            <li>Large-scale recommender systems</li>
          </ul>
        </li>
        <li>Key challenges in understanding GNN predictions</li>
      </ul>
    </li>
    <li><strong>Part II: Explainability in Graphs (XAI)</strong> (30 mins)
      <ul>
        <li>The black-box problem in GNNs and its implications</li>
        <li>Overview of Explainable AI (XAI) techniques for graphs</li>
        <li>Factual explanations vs. Counterfactual explanations</li>
        <li>A deep dive into existing factual explainers:
          <ul>
            <li>GNNExplainer: Strengths and limitations</li>
            <li>GraphLIME: Local interpretability in GNNs</li>
            <li>Other noteworthy post-hoc explanation methods</li>
          </ul>
        </li>
      </ul>
    </li>
    <li><strong>Part III: undamentals of Graph Counterfactual Explainability (GCE)</strong> (45 mins)
      <ul>
        <li>Defining counterfactual explanations in the graph domain</li>
        <li>Why counterfactuals? Advantages over factual explanations</li>
        <li>Challenges in generating counterfactuals for graphs:
          <ul>
            <li>Structural constraints in graphs</li>
            <li>Ensuring plausibility and feasibility of counterfactuals</li>
            <li>Computational complexity concerns</li>
          </ul>
        </li>
        <li>Taxonomy of GCE methods:
          <ul>
            <li><strong>Instance-level explainers</strong>
              <ul>
                <li>Search-based approaches</li>
                <li>Heuristic-based approaches</li>
                <li>Learning-based approaches</li>
              </ul>
            </li>
            <li><strong>Model-level explainers</strong>
              <ul>
                <li>Global explanations for GNNs</li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li><strong>Part IV: Evaluating Graph Counterfactual Explanations</strong> (30 mins)
      <ul>
        <li>Overview of benchmarking datasets:
          <ul>
            <li>Synthetic vs. real-world graph datasets</li>
            <li>Domain-specific datasets: Social networks, molecular graphs, and financial transactions</li>
          </ul>
        </li>
        <li>Evaluation metrics and assessment frameworks:
          <ul>
            <li>Validity and plausibility of counterfactuals</li>
            <li>Proximity and sparsity constraints</li>
            <li>Fidelity to the underlying GNN model</li>
          </ul>
        </li>
        <li>Discussion on robustness and fairness in GCE methods</li>
      </ul>
    </li>
    <li><strong>Part V: Counterfactual Explainability in Evolving Graphs</strong> (40 mins)
      <ul>
        <li>What makes dynamic graphs different?
          <ul>
            <li>Temporal dependencies and evolving structures</li>
            <li>Distribution shifts and their impact on GNN predictions</li>
          </ul>
        </li>
        <li>Challenges in applying counterfactual explanations to dynamic graphs:
          <ul>
            <li>Stability and consistency of counterfactuals over time</li>
            <li>Identifying actionable interventions in dynamic environments</li>
            <li>Handling streaming data and online learning settings</li>
          </ul>
        </li>
        <li>Existing approaches for counterfactual explainability in dynamic graphs:
          <ul>
            <li>Adapting instance-based explainers to evolving graphs</li>
            <li>Extending model-level explanations for temporal settings</li>
            <li>Learning-based techniques for robust counterfactuals in dynamic graphs</li>
          </ul>
        </li>
      </ul>
    </li>
    <li><strong>Part VI: Frameworks In-the-Wild</strong> (35 mins)
      <ul>
        <li>Introduction to the challenges of developing and evaluating GCE methods</li>
        <li>GRETEL’s design, core components, and their interaction</li>
        <li>Basic explanation pipeline and evaluation</li>
      </ul>
    </li>
    <li><strong>Part VII: What's next?</strong> (10 mins)
      <ul>
        <li>Open discussion on the future trends and development in the research/industry area</li>
      </ul>
    </li>
  </ul>  
</div>
<p align="center"><strong>Figure 1: The brief outline of the tutorial with its time scheduling.</strong></p>

<p>During the first part of the tutorial, we introduce GNNs [<a href="#scarselli2008graph">2</a>] and their underlying message-passing mechanism to solve graph prediction problems. We will delve into the different types of GNNs and their application in real-world problems [<a href="#wu2020comprehensive">3</a>], such as protein-protein interaction, drug-target affinity prediction, and anomaly detection in social networks.</p>

<p>In the second part, we provide the reader with the challenges of deploying black-box models in critical scenarios and how post-hoc interpretability helps uncover <em>“what is happening under the hood”</em>. Here, we introduce factual explanations [<a href="#yuan2022explainability">4</a>] and briefly revisit the most interesting methods in this category, namely GNNExplainer [<a href="#ying2019gnnexplainer">5</a>], and GraphLIME [<a href="#huang2022graphlime">6</a>].</p>

<p>In the third part, we formalise the definition of Graph Counterfactual Explanation (GCE). We present a taxonomy of the most important references [<a href="#prado2022survey">1</a>], categorised as in Table 1, including search-based explainers [<a href="#liu2021multi">7</a>] , heuristic-based ones 
[<a href="#abrate2021counterfactual">8</a>,<a href="#bajaj2021robust">9</a>,<a href="#wellawatte2022model">10</a>], learning-based ones [<a href="#bajaj2021robust">9</a>,<a href="#cai2022probability">11</a>,<a href="#lucic2022cf">12</a>,<a href="#ma2022clear">13</a>,<a href="#nguyen2022explaining">14</a>,<a href="#numeroso2021meg">15</a>,<a href="#sun2021preserve">16</a>,<a href="#tan2022learning">17</a>,<a href="#wu2021counterfactual">18</a>], and global-level explanation methods [<a href="#huang2023global">19</a>]. Additionally, we list the most common benchmarking datasets and a set of evaluation metrics [<a href="#yuan2022explainability">4</a>,<a href="#guidotti2022counterfactual">20</a>] necessary to assess the (dis)advantages of each counterfactual explainer in the literature.</p>

<figure>
  <p align="center">
    <a href="https://doi.org/10.1145/3618105">
     <img style="width:  100%;" src="/events/imgs/gce_tutorial_references.png" alt="The most important references that will be covered in the tutorial." /></a>
     <figcaption>  
          <p align="center"><strong>Table 1: The most important references that will be covered in the tutorial.</strong></p>  
     </figcaption> 
     </p>
 </figure>
<p><br /></p>

<h3 class="pt-3" id="Acknowledgement">Acknowledgement</h3>
<figure>
  <p align="center">
    <a href="https://www.supercomputing-icsc.it/">
     <img style="width:  33%;" src="/events/imgs/xcicsc.png" alt="ICSC, Centro Nazionale di Ricerca in High Performance Computing, Big Data e Quantum Computing" /></a>
     </p>
</figure>
<p><em>“Graphs Counterfactual Explainability: A Comprehensive Landscape (Tutorial at AAAI 2024)” event was organised as part of the ICSC, Centro Nazionale di Ricerca in High Performance Computing, Big Data e Quantum Computing (Prot. CN00000013) initiatives aimed at disseminating to new communities the project results and creating bridging opportunities. 
ICSC, Centro Nazionale di Ricerca in High Performance Computing, Big Data e Quantum Computing receives funding from European Union – NextGenerationEU – National Recovery and Resilience Plan (Piano Nazionale di Ripresa e Resilienza, PNRR) – Project: CN00000013 – NATIONAL CENTRE FOR HPC, BIG DATA AND QUANTUM COMPUTING, Avviso pubblico D.D. n. 3138 del 16.12.2021, rettificato con D.D.3175 del 18.12.2021</em></p>

<h3 class="pt-3" id="Speakers">Meet the Speakers</h3>
<h4 class="pt-3" id="Bardh">Bardh Prenkaj</h4>
<p>is a postdoc at the Technical University of Munich, Chair of Responsible Data Science, moving from a first postdoc position (10/2022 - 09/2024) held at the Computer Science Department in the Sapienza University of Rome. His research interests lie on the intersection of Trustworthy Machine Learning and AI for Healthcare. Recently, he has been dedicated to understanding the trade-off between transparency and performance in tasks such as Graph Classification, Anomaly Detection, and Shortcut Identification.</p>

<h4 class="pt-3" id="Andrea">Andrea D'Angelo</h4>
<p>is a Ph.D. student in Computer Science at the University of L’Aquila, where he previously completed his Bachelor’s and Master’s degrees in 2019 and 2022, respectively. In 2025, he spent a visiting research period at Aarhus University in Denmark. His research focuses on Responsible Data Science, particularly Machine Unlearning, Information Retrieval, and Bias and Fairness.</p>

<h4 class="pt-3" id="Stratis">Efstratios Zaradoukas</h4>
<p>is a Ph.D. student at the Chair of Responsible Data Science, Technical University of Munich. He earned his Master’s degree in Electrical and Computer Engineering at University of Patras, Greece. He has experience in fields such as Image Captioning, Image Inpainting and Recommender Systems. His primary research focuses on explainability for autoregressive generative models, and machine unlearning.</p>

<h4 class="pt-3" id="Mario">Mario Alfonso Prado-Romero</h4>
<p>obtained his PhD at the Gran Sasso Science Institute in Italy. His primary research focuses on the confluence of Explainable AI and Graph Neural Networks. Before this, he gained experience in relevant fields such as Anomaly Detection, Data Mining, and Information Retrieval. Notably, he is the key contributor to the GRETEL project, which offers a comprehensive framework for developing and assessing Graph Counterfactual Explanations. Additionally, he was selected by NEC Laboratories Europe as the only intern of the Human-Centric AI group in 2023, where his expertise in eXplainable Artificial Intelligence (XAI) will be applied to Graph Neural Networks for Biomedical Applications.</p>

<h4 class="pt-3" id="Giovanni">Giovanni Stilo</h4>
<p>is a Computer Science and Data Science associate professor at the University of L’Aquila, where he leads the Master’s Degree in Data Science, and he is part of the <a href="/">Artificial Intelligence and Information Mining collective</a>. He received his PhD in Computer Science in 2013, and in 2014, he was a visiting researcher at Yahoo! Labs in Barcelona. His research interests are related to machine learning, data mining, and artificial intelligence, with a special interest in (but not limited to) trustworthiness aspects such as Bias, Fairness, and Explainability. 
Specifically, he is the head of the <a href="/projects/gretel.html">GRETEL</a> project devoted to empowering the research in the Graph Counterfactual Explainability field.
He has co-organized a long series (2020-2023) of top-tier International <a href="/events.html">events</a> and Journal Special Issues focused on Bias and Fairness in Search and Recommendation. He serves on the editorial boards of IEEE, ACM, Springer, and Elsevier Journals such as TITS, TKDE, DMKD, AI, KAIS, and AIIM. 
He is responsible for New technologies for data collection, preparation, and analysis of the Territory Aperti project and coordinator of the activities on <em>“Responsible Data Science and Training”</em> of <em><a href="https://pnrr.sobigdata.it/">PNRR SoBigData.it project</a></em>, and PI of the <em>“FAIR-EDU: Promote FAIRness in EDUcation Institutions”</em> project. During his academic growth, he devoted much of his attention to teaching and tutoring, where he worked on more than 30 different national and international theses (of B.Sc., M.Sc., and PhD levels). In more than ten years of academia, he provided university-level courses for ten different topics and grades in the scientific field of Computer and Data Science.
<!--Full CV available at the \href{https://www.disim.univaq.it/show.php?token=c174d4ed4396d5480f0da2dcfe13f94f&id=g.stilo}{link}--></p>

<h3 class="pt-3" id="Bibliography">Bibliography</h3>
<p><a id="prado2022survey">[1]</a> 
Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo, and Fosca Giannotti. 
<em>A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation, and Research Challenges.</em>
ACM Comput. Surv. (September 2023). <a href="https://doi.org/10.1145/3618105">https://doi.org/10.1145/3618105</a></p>

<p><a id="scarselli2008graph">[2]</a> 
F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner and G. Monfardini, <em>The Graph Neural Network Model</em>, in IEEE Transactions on Neural Networks, vol. 20, no. 1, pp. 61-80, Jan. 2009, <a href="https://doi.org/10.1109/TNN.2008.2005605">https://doi.org/10.1109/TNN.2008.2005605</a></p>

<p><a id="wu2020comprehensive">[3]</a> 
Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang and P. S. Yu, <em>A Comprehensive Survey on Graph Neural Networks</em>, in IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 1, pp. 4-24, Jan. 2021, <a href="https://doi.org/10.1109/TNNLS.2020.2978386">https://doi.org/10.1109/TNNLS.2020.2978386</a></p>

<p><a id="yuan2022explainability">[4]</a> 
H. Yuan, H. Yu, S. Gui and S. Ji, <em>Explainability in Graph Neural Networks: A Taxonomic Survey</em>, in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 5, pp. 5782-5799, 1 May 2023, <a href="https://doi.org/10.1109/TPAMI.2022.3204236">https://doi.org/10.1109/TPAMI.2022.3204236</a></p>

<p><a id="ying2019gnnexplainer">[5]</a> 
Ying, Z., Bourgeois, D., You, J., Zitnik, M., and Leskovec,J., 2019. <em>Gnnexplainer: Generating explanations for graph
neural networks</em>. Advances in neural information processing systems, 32.</p>

<p><a id="huang2022graphlime">[6]</a> 
Q. Huang, M. Yamada, Y. Tian, D. Singh and Y. Chang, <em>GraphLIME: Local Interpretable Model Explanations for Graph Neural Networks</em>, in IEEE Transactions on Knowledge and Data Engineering, vol. 35, no. 7, pp. 6968-6972, 1 July 2023, <a href="https://doi.org/10.1109/TKDE.2022.3187455">https://doi.org/10.1109/TKDE.2022.3187455</a></p>

<p><a id="liu2021multi">[7]</a> 
Y. Liu, C. Chen, Y. Liu, X. Zhang and S. Xie, <em>Multi-objective Explanations of GNN Predictions</em>, 2021 IEEE International Conference on Data Mining (ICDM), Auckland, New Zealand, 2021, pp. 409-418, <a href="https://doi.org/10.1109/ICDM51629.2021.00052">https://doi.org/10.1109/ICDM51629.2021.00052</a></p>

<p><a id="abrate2021counterfactual">[8]</a> 
Carlo Abrate and Francesco Bonchi. 2021. <em>Counterfactual Graphs for Explainable Classification of Brain Networks</em>. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD ‘21). Association for Computing Machinery, New York, NY, USA, 2495–2504. <a href="https://doi.org/10.1145/3447548.3467154">https://doi.org/10.1145/3447548.3467154</a></p>

<p><a id="bajaj2021robust">[9]</a> 
Bajaj, M., Chu, L., Xue, Z., Pei, J., Wang, L., Lam, P.,and Zhang, Y. <em>Robust counterfactual explanations on graph neural networks</em>. Advances in neural information processing systems, 34.</p>

<p><a id="wellawatte2022model">[10]</a> 
Wellawatte GP, Seshadri A, White AD. <em>Model agnostic generation of counterfactual explanations for molecules</em>. Chem Sci. 2022 Feb 16;13(13):3697-3705. <a href="https://doi.org/10.1039/d1sc05259d">https://doi.org/10.1039/d1sc05259d</a></p>

<p><a id="cai2022probability">[11]</a> 
Cai, R., Zhu, Y., Chen, X., Fang, Y., Wu, M., Qiao,J., and Hao, Z. 2022. <em>On the Probability of Necessity and Sufficiency of Explaining Graph Neural Networks: A Lower Bound Optimization Approach</em>. arXiv preprint arXiv:2212.07056</p>

<p><a id="lucic2022cf">[12]</a> 
Ana Lucic, Maartje A. Ter Hoeve, Gabriele Tolomei, Maarten De Rijke, Fabrizio Silvestri, <em>CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks</em>, in  Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, PMLR 151:4499-4511, 2022.</p>

<p><a id="ma2022clear">[13]</a> 
Ma, J.; Guo, R.; Mishra, S.; Zhang, A.; and Li, J., 2022. <em>CLEAR: Generative Counterfactual Explanations on Graphs</em>. Advances in neural information processing systems, 35, 25895–25907.</p>

<p><a id="nguyen2022explaining">[14]</a> 
T. M. Nguyen, T. P. Quinn, T. Nguyen and T. Tran, <em>Explaining Black Box Drug Target Prediction Through Model Agnostic Counterfactual Samples</em>, in IEEE/ACM Transactions on Computational Biology and Bioinformatics, vol. 20, no. 2, pp. 1020-1029, 1 March-April 2023, <a href="https://doi.org/10.1109/TCBB.2022.3190266">https://doi.org/10.1109/TCBB.2022.3190266</a></p>

<p><a id="numeroso2021meg">[15]</a> 
Numeroso, Danilo and Bacciu, Davide, <em>MEG: Generating Molecular Counterfactual Explanations for Deep Graph Networks</em>, 2021 International Joint Conference on Neural Networks (IJCNN). <a href="https://doi.org/10.1109/IJCNN52387.2021.9534266">https://doi.org/10.1109/IJCNN52387.2021.9534266</a></p>

<p><a id="sun2021preserve">[16]</a> 
Sun, Y., Valente, A., Liu, S., &amp; Wang, D. (2021). Preserve, Promote, or Attack? GNN Explanation via Topology Perturbation. ArXiv. <a href="https://arxiv.org/abs/2103.13944">https://arxiv.org/abs/2103.13944</a></p>

<p><a id="tan2022learning">[17]</a> 
Juntao Tan, Shijie Geng, Zuohui Fu, Yingqiang Ge, Shuyuan Xu, Yunqi Li, and Yongfeng Zhang. 2022. <em>Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning</em>. In Proceedings of the ACM Web Conference 2022 (WWW ‘22).<a href="https://doi.org/10.1145/3485447.3511948">https://doi.org/10.1145/3485447.3511948</a></p>

<p><a id="wu2021counterfactual">[18]</a> 
Wu, H.; Chen, W.; Xu, S.; and Xu, B. 2021. <em>Counterfactual Supporting Facts Extraction for Explainable Medical Record Based Diagnosis with Graph Network</em>. In Proc. of
the 2021 Conf. of the North American Chapter of the Assoc. for Comp. Linguistics: Human Lang. Techs., 1942–1955. <a href="https://aclanthology.org/2021.naacl-main.156/">https://aclanthology.org/2021.naacl-main.156/</a></p>

<p><a id="huang2023global">[19]</a>
Zexi Huang, Mert Kosan, Sourav Medya, Sayan Ranu, and Ambuj Singh. 2023. <em>Global Counterfactual Explainer for Graph Neural Networks</em>. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM ‘23). Association for Computing Machinery, New York, NY, USA, 141–149. <a href="https://doi.org/10.1145/3539597.3570376">https://doi.org/10.1145/3539597.3570376</a></p>

<p><a id="guidotti2022counterfactual">[20]</a> 
Guidotti, R. <em>Counterfactual explanations and how to find them: literature review and benchmarking</em>. Data Min Knowl Disc (2022). <a href="https://doi.org/10.1007/s10618-022-00831-6">https://doi.org/10.1007/s10618-022-00831-6</a></p>

<p><br /></p>




            <div class="footer">
                <p>
                    © Copyright 2019-2025 - Artificial Intelligence and Information Mining - All rights reserved.
                </p>
            </div>

        </div> <!-- /container -->

        <!-- Support retina images. -->
        <script type="text/javascript"
                src="/js/srcset-polyfill.js"></script>
        <!-- Bootstrap JS-->
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.3/dist/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
        <!-- Global site tag (gtag.js) - Google Analytics -->
	    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-160388153-1"></script>
	    <script>
	        window.dataLayer = window.dataLayer || [];
	        function gtag(){dataLayer.push(arguments);}
	        gtag('js', new Date());

	        gtag('config', 'UA-160388153-1');
	    </script>

       
    </body>
</html>
