<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Artificial Intelligence and Information Mining - Research Group: Graphs’ Counterfactual Explainability Landscape: current state and frontiers</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta http-equiv="Permissions-Policy" content="interest-cohort=()">
        <!-- bootstrap -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
        <!-- fontawesome -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <script src="https://kit.fontawesome.com/be7d5ac8d8.js" crossorigin="anonymous"></script>
        <!-- favicon -->
        <link rel="apple-touch-icon" sizes="180x180" href="/img/fav/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/img/fav/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/img/fav/favicon-16x16.png">
        <link rel="manifest" href="/site.webmanifest">  
        <!-- our custom css -->
        <link rel="stylesheet" href="/css/group.css">
    </head>
    <body>
        <div class="container">
            <!-- This is a bit nasty, but it basically says be a column first, and on larger screens be a spaced out row -->
            <div class="sticky-top header d-flex 
                        flex-column
                        flex-md-row justify-content-md-between">
                <a href="/" class="">
                    <img src="/img/AIIM-Logo.svg"
                         srcset="/img/AIIM-Logo.svg 2x"
                         alt="AIIM - Artificial Intelligence and Information Mining research group." id="logo">
                </a>
                <ul class="nav nav-pills justify-content-center">

                    
                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/">
                                Home
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/news.html">
                                News
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/people.html">
                                People
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/research.html">
                                Research
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link active"
                               href="/events.html">
                                Events
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/code.html">
                                Resources
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/publications.html">
                                Publications
                            </a>
                        </li>

                    

                </ul>
            </div>

            
                
                <a href="https://beyondaccuracy-userprofiling.github.io/xai-it-2023/program.html" class="">
                
                <img src="/events/imgs/AIxIA2023.png"
                     alt="Graphs’ Counterfactual Explainability Landscape: current state and frontiers"
                     style="max-width: 400px"
                     class="img-fluid mx-auto d-block mb-4"/>
                
                </a>
                
            

            
                <h2 class="pt-3">Graphs’ Counterfactual Explainability Landscape: current state and frontiers</h2>
            
            
                <h3 class="pt-3">Invited talk XAI.it 2023 - 4th Italian Workshop on Explainable Artificial Intelligence | co-located with AIxIA 2023 on 8, Nov. 2023</h3>
            

            <br>
<h3> Organisers </h3>
<section class="people project-people">
    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="/"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Prof. Giovanni Stilo"
             title="Prof. Giovanni Stilo"
             src="/img/people/Stilo.jpeg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="/"> Prof. Giovanni Stilo </a>
     </h6>
            
                <div class="bio">University of L'Aquila</div>
            
        </div>
    </div>


    
</section>
<p><a href="/events/imgs/XAI.it-Graphs_Counterfactual_Explainability_Landscape.pdf" target="_blank">Slides are available here.</a></p>
<div class="highlight" height="400px"> 
        <embed src="/events/imgs/XAI.it-Graphs_Counterfactual_Explainability_Landscape.pdf" type="application/pdf" width="100%" height="450px" />
</div>
<p><br /></p>
<div class="notes">
<h3><a href="https://teams.microsoft.com/l/meetup-join/19%3ameeting_MzNhYjk3M2MtZDRlZi00ZGQwLWJlNDktMGNiZWVkZmY0YjYz%40thread.v2/0?context=%7b%22Tid%22%3a%22ffb4df68-f464-458c-a546-00fb3af66f6a%22%2c%22Oid%22%3a%2274018dec-6e86-4ea3-ad54-5015bee4718b%22%7d" target="_blank">Live Stream of the event (9:00-13:00 CET, Wednesday, 8 Nov. 2023).</a></h3>
</div>

<h3 class="pt-3">Table of contents</h3>
<ul>
  <li><a href="#Abstract">Abstract</a></li>
  <li><a href="#Events">Upcoming events at AAAI 2024</a></li>
  <li><a href="#Giovanni">Meet the speaker</a></li>
  <li><a href="#Bibliography">Bibliography</a></li>
  <li><a href="#Acknowledgement">Acknowledgement</a></li>
</ul>

<h3 class="pt-3" id="Abstract">Abstract</h3>
<p>Counterfactual Explanation (CE) techniques have garnered attention as a means to provide insights to the users engaging with AI systems. While extensively researched in domains such as medical imaging and autonomous vehicles, Graph Counterfactual Explanation (GCE) methods have been comparatively under-explored. GCEs generate a new graph akin to the original one, having a different outcome grounded on the underlying predictive model. During this presentation, we take you on a journey across the GCE, commencing with foundational concepts. Next, we introduce the categorization of explainers, emphasize key tools essential for initiating work in this field, explore the latest advancements, offer a visual comparison of various generative methods, and conclude with our final remarks.</p>

<figure>
  <p align="center">
    <a href="https://doi.org/10.1145/3618105">
     <img style="width:  100%;" src="/events/imgs/gce_tutorial_references.png" alt="Table 1: The most important references of the research topic." /></a>
     <figcaption>  
          <p align="center"><strong>Table 1: The most important references of the research topic.</strong></p>  
     </figcaption> 
     </p>
 </figure>
<!--<h3 class="pt-3" >Highlights</h3>-->
<p>The talk is partially based on on ACM Computing Survey: <a href="https://dl.acm.org/doi/abs/10.1145/3618105">A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation, and Research Challenges</a>
Use the following BibTeX to cite our paper.</p>

<figure class="highlight"><pre><code class="language-cpp" data-lang="cpp"><span class="err">@</span><span class="n">article</span><span class="p">{</span><span class="mf">10.1145</span><span class="o">/</span><span class="mi">3618105</span><span class="p">,</span>
    <span class="n">author</span> <span class="o">=</span> <span class="p">{</span><span class="n">Prado</span><span class="o">-</span><span class="n">Romero</span><span class="p">,</span> <span class="n">Mario</span> <span class="n">Alfonso</span> <span class="n">and</span> <span class="n">Prenkaj</span><span class="p">,</span> <span class="n">Bardh</span> <span class="n">and</span> <span class="n">Stilo</span><span class="p">,</span> <span class="n">Giovanni</span> <span class="n">and</span> <span class="n">Giannotti</span><span class="p">,</span> <span class="n">Fosca</span><span class="p">},</span>
    <span class="n">title</span> <span class="o">=</span> <span class="p">{</span><span class="n">A</span> <span class="n">Survey</span> <span class="n">on</span> <span class="n">Graph</span> <span class="n">Counterfactual</span> <span class="n">Explanations</span><span class="o">:</span> <span class="n">Definitions</span><span class="p">,</span> <span class="n">Methods</span><span class="p">,</span> <span class="n">Evaluation</span><span class="p">,</span> <span class="n">and</span> <span class="n">Research</span> <span class="n">Challenges</span><span class="p">},</span>
    <span class="n">year</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2023</span><span class="p">},</span>
    <span class="n">publisher</span> <span class="o">=</span> <span class="p">{</span><span class="n">Association</span> <span class="k">for</span> <span class="n">Computing</span> <span class="n">Machinery</span><span class="p">},</span>
    <span class="n">address</span> <span class="o">=</span> <span class="p">{</span><span class="n">New</span> <span class="n">York</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="n">USA</span><span class="p">},</span>
    <span class="n">issn</span> <span class="o">=</span> <span class="p">{</span><span class="mo">0360</span><span class="o">-</span><span class="mo">0300</span><span class="p">},</span>
    <span class="n">url</span> <span class="o">=</span> <span class="p">{</span><span class="n">https</span><span class="o">:</span><span class="c1">//doi.org/10.1145/3618105},</span>
    <span class="n">doi</span> <span class="o">=</span> <span class="p">{</span><span class="mf">10.1145</span><span class="o">/</span><span class="mi">3618105</span><span class="p">},</span>
    <span class="n">journal</span> <span class="o">=</span> <span class="p">{</span><span class="n">ACM</span> <span class="n">Computing</span> <span class="n">Surveys</span><span class="p">},</span>
    <span class="n">month</span> <span class="o">=</span> <span class="p">{</span><span class="n">sep</span><span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<!--<h3 class="pt-3" id="Materials">Materials</h3>
We will upload essential materials, including key references, presentation slides, and related events right here. Keep an eye out for updates and stay tuned for more information!-->

<h3 class="pt-3" id="Events">Upcoming events at AAAI 2024</h3>
<p>We are delighted to announce that our proposals for both a tutorial and a lab have been accepted for presentation at the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24), scheduled to take place at the Vancouver Convention Centre in Vancouver, British Columbia, Canada, from February 20 to February 27, 2024.</p>

<p>Do not to miss our tutorial session titled:</p>
<ul>
  <li><strong>“Graphs Counterfactual Explainability: A Comprehensive Landscape”</strong> <a href="/events/AAAI_2024_Graphs_Counterfactual_Explainability_A_Comprehensive_Landscape.html">Website of the Tutorial</a></li>
</ul>

<p>and the closely associated laboratory session named:</p>
<ul>
  <li><strong>“Digging into the Landscape of Graphs Counterfactual Explainability.”</strong> <a href="/events/AAAI_2024_Digging_into_the_Landscape_of_Graphs_Counterfactual_Explainability.html">Website of the Laboratory</a></li>
</ul>

<h3 class="pt-3" id="Giovanni">Giovanni Stilo</h3>
<p>is a Computer Science and Data Science associate professor at the University of L’Aquila, where he leads the Master’s Degree in Data Science, and he is part of the <a href="/">Artificial Intelligence and Information Mining collective</a>. He received his PhD in Computer Science in 2013, and in 2014, he was a visiting researcher at Yahoo! Labs in Barcelona. His research interests are related to machine learning, data mining, and artificial intelligence, with a special interest in (but not limited to) trustworthiness aspects such as Bias, Fairness, and Explainability. 
Specifically, he is the head of the <a href="/code.html">GRETEL</a> project devoted to empowering the research in the Graph Counterfactual Explainability field.
He has co-organized a long series (2020-2023) of top-tier International <a href="/events.html">events</a> and Journal Special Issues focused on Bias and Fairness in Search and Recommendation. He serves on the editorial boards of IEEE, ACM, Springer, and Elsevier Journals such as TITS, TKDE, DMKD, AI, KAIS, and AIIM. 
He is responsible for New technologies for data collection, preparation, and analysis of the Territory Aperti project and coordinator of the activities on <em>“Responsible Data Science and Training”</em> of <em><a href="https://pnrr.sobigdata.it/">PNRR SoBigData.it project</a></em>, and PI of the <em>“FAIR-EDU: Promote FAIRness in EDUcation Institutions”</em> project. 
During his academic growth, he devoted much of his attention to teaching and tutoring, where he worked on more than 30 different national and international theses (of B.Sc., M.Sc., and PhD levels). In more than ten years of academia, he provided university-level courses for ten different topics and grades in the scientific field of Computer and Data Science.</p>

<h3 class="pt-3" id="Bibliography">Bibliography</h3>
<p><a id="prado2022survey">[1]</a> 
Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo, and Fosca Giannotti. 
<em>A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation, and Research Challenges.</em>
ACM Comput. Surv. (September 2023). <a href="https://doi.org/10.1145/3618105">https://doi.org/10.1145/3618105</a></p>

<p><a id="prado2022gretel">[2]</a> 
Mario Alfonso Prado-Romero and Giovanni Stilo. 2022. GRETEL: Graph Counterfactual Explanation Evaluation Framework. In Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management (CIKM ‘22). Association for Computing Machinery, New York, NY, USA, 4389–4393. <a href="https://doi.org/10.1145/3511808.3557608">https://doi.org/10.1145/3511808.3557608</a></p>

<p><a id="prado2023developing">[3]</a> 
Mario Alfonso Prado-Romero, Bardh Prenkaj, and Giovanni Stilo. 2023. <em>Developing and Evaluating Graph Counterfactual Explanation with GRETEL</em>. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM ‘23). Association for Computing Machinery, New York, NY, USA, 1180–1183. <a href="https://doi.org/10.1145/3539597.3573026">https://doi.org/10.1145/3539597.3573026</a></p>

<p><a id="scarselli2008graph">[4]</a> 
F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner and G. Monfardini, <em>The Graph Neural Network Model</em>, in IEEE Transactions on Neural Networks, vol. 20, no. 1, pp. 61-80, Jan. 2009, <a href="https://doi.org/10.1109/TNN.2008.2005605">https://doi.org/10.1109/TNN.2008.2005605</a></p>

<p><a id="wu2020comprehensive">[5]</a> 
Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang and P. S. Yu, <em>A Comprehensive Survey on Graph Neural Networks</em>, in IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 1, pp. 4-24, Jan. 2021, <a href="https://doi.org/10.1109/TNNLS.2020.2978386">https://doi.org/10.1109/TNNLS.2020.2978386</a></p>

<p><a id="huang2022graphlime">[6]</a> 
Q. Huang, M. Yamada, Y. Tian, D. Singh and Y. Chang, <em>GraphLIME: Local Interpretable Model Explanations for Graph Neural Networks</em>, in IEEE Transactions on Knowledge and Data Engineering, vol. 35, no. 7, pp. 6968-6972, 1 July 2023, <a href="https://doi.org/10.1109/TKDE.2022.3187455">https://doi.org/10.1109/TKDE.2022.3187455</a></p>

<p><a id="liu2021multi">[7]</a> 
Y. Liu, C. Chen, Y. Liu, X. Zhang and S. Xie, <em>Multi-objective Explanations of GNN Predictions</em>, 2021 IEEE International Conference on Data Mining (ICDM), Auckland, New Zealand, 2021, pp. 409-418, <a href="https://doi.org/10.1109/ICDM51629.2021.00052">https://doi.org/10.1109/ICDM51629.2021.00052</a></p>

<p><a id="abrate2021counterfactual">[8]</a> 
Carlo Abrate and Francesco Bonchi. 2021. <em>Counterfactual Graphs for Explainable Classification of Brain Networks</em>. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD ‘21). Association for Computing Machinery, New York, NY, USA, 2495–2504. <a href="https://doi.org/10.1145/3447548.3467154">https://doi.org/10.1145/3447548.3467154</a></p>

<p><a id="bajaj2021robust">[9]</a> 
Bajaj, M., Chu, L., Xue, Z., Pei, J., Wang, L., Lam, P.,and Zhang, Y. <em>Robust counterfactual explanations on graph neural networks</em>. Advances in neural information processing systems, 34.</p>

<p><a id="wellawatte2022model">[10]</a> 
Wellawatte GP, Seshadri A, White AD. <em>Model agnostic generation of counterfactual explanations for molecules</em>. Chem Sci. 2022 Feb 16;13(13):3697-3705. <a href="https://doi.org/10.1039/d1sc05259d">https://doi.org/10.1039/d1sc05259d</a></p>

<p><a id="cai2022probability">[11]</a> 
Cai, R., Zhu, Y., Chen, X., Fang, Y., Wu, M., Qiao,J., and Hao, Z. 2022. <em>On the Probability of Necessity and Sufficiency of Explaining Graph Neural Networks: A Lower Bound Optimization Approach</em>. arXiv preprint arXiv:2212.07056</p>

<p><a id="lucic2022cf">[12]</a> 
Ana Lucic, Maartje A. Ter Hoeve, Gabriele Tolomei, Maarten De Rijke, Fabrizio Silvestri, <em>CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks</em>, in  Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, PMLR 151:4499-4511, 2022.</p>

<p><a id="ma2022clear">[13]</a> 
Ma, J.; Guo, R.; Mishra, S.; Zhang, A.; and Li, J., 2022. <em>CLEAR: Generative Counterfactual Explanations on Graphs</em>. Advances in neural information processing systems, 35, 25895–25907.</p>

<p><a id="nguyen2022explaining">[14]</a> 
T. M. Nguyen, T. P. Quinn, T. Nguyen and T. Tran, <em>Explaining Black Box Drug Target Prediction Through Model Agnostic Counterfactual Samples</em>, in IEEE/ACM Transactions on Computational Biology and Bioinformatics, vol. 20, no. 2, pp. 1020-1029, 1 March-April 2023, <a href="https://doi.org/10.1109/TCBB.2022.3190266">https://doi.org/10.1109/TCBB.2022.3190266</a></p>

<p><a id="numeroso2021meg">[15]</a> 
Numeroso, Danilo and Bacciu, Davide, <em>MEG: Generating Molecular Counterfactual Explanations for Deep Graph Networks</em>, 2021 International Joint Conference on Neural Networks (IJCNN). <a href="https://doi.org/10.1109/IJCNN52387.2021.9534266">https://doi.org/10.1109/IJCNN52387.2021.9534266</a></p>

<p><a id="sun2021preserve">[16]</a> 
Sun, Y., Valente, A., Liu, S., &amp; Wang, D. (2021). Preserve, Promote, or Attack? GNN Explanation via Topology Perturbation. ArXiv. <a href="https://arxiv.org/abs/2103.13944">https://arxiv.org/abs/2103.13944</a></p>

<p><a id="tan2022learning">[17]</a> 
Juntao Tan, Shijie Geng, Zuohui Fu, Yingqiang Ge, Shuyuan Xu, Yunqi Li, and Yongfeng Zhang. 2022. <em>Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning</em>. In Proceedings of the ACM Web Conference 2022 (WWW ‘22).<a href="https://doi.org/10.1145/3485447.3511948">https://doi.org/10.1145/3485447.3511948</a></p>

<p><a id="wu2021counterfactual">[18]</a> 
Wu, H.; Chen, W.; Xu, S.; and Xu, B. 2021. <em>Counterfactual Supporting Facts Extraction for Explainable Medical Record Based Diagnosis with Graph Network</em>. In Proc. of
the 2021 Conf. of the North American Chapter of the Assoc. for Comp. Linguistics: Human Lang. Techs., 1942–1955. <a href="https://aclanthology.org/2021.naacl-main.156/">https://aclanthology.org/2021.naacl-main.156/</a></p>

<p><a id="huang2023global">[19]</a>
Zexi Huang, Mert Kosan, Sourav Medya, Sayan Ranu, and Ambuj Singh. 2023. <em>Global Counterfactual Explainer for Graph Neural Networks</em>. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM ‘23). Association for Computing Machinery, New York, NY, USA, 141–149. <a href="https://doi.org/10.1145/3539597.3570376">https://doi.org/10.1145/3539597.3570376</a></p>

<h3 class="pt-3" id="Acknowledgement">Acknowledgement</h3>
<figure>
  <p align="center">
    <a href="https://pnrr.sobigdata.it/">
     <img style="width:  33%;" src="/events/imgs/SoBigData.svg" alt="The most important references that will be covered in the tutorial." /></a>
     </p>
</figure>
<p><em>“Digging into the Landscape of Graphs Counterfactual Explainability (Laboratory at AAAI 2024)” event was organised as part of the SoBigData.it project (Prot. IR0000013 - Call n. 3264 of 12/28/2021) initiatives aimed at training new users and communities in the usage of the research infrastructure (SoBigData.eu). SoBigData.it receives funding from European Union – NextGenerationEU – National Recovery and Resilience Plan (Piano Nazionale di Ripresa e Resilienza, PNRR) – Project: “SoBigData.it – Strengthening the Italian RI for Social Mining and Big Data Analytics” – Prot. IR0000013 – Avviso n. 3264 del 28/12/2021.</em></p>




            <div class="footer">
                <p>
                    © Copyright 2019-2023 - Artificial Intelligence and Information Mining - All rights reserved.
                </p>
            </div>

        </div> <!-- /container -->

        <!-- Support retina images. -->
        <script type="text/javascript"
                src="/js/srcset-polyfill.js"></script>
        <!-- Bootstrap JS-->
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.3/dist/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
        <!-- Global site tag (gtag.js) - Google Analytics -->
	    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-160388153-1"></script>
	    <script>
	        window.dataLayer = window.dataLayer || [];
	        function gtag(){dataLayer.push(arguments);}
	        gtag('js', new Date());

	        gtag('config', 'UA-160388153-1');
	    </script>
    </body>
</html>
