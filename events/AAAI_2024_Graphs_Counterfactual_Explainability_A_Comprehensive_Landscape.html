<!DOCTYPE html>
<html>
    <head>
        <title>Artificial Intelligence and Information Mining - Research Group: Graphs Counterfactual Explainability: A Comprehensive Landscape(AAAI 2024)</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta http-equiv="Permissions-Policy" content="interest-cohort=()">
        <link rel="stylesheet" href="/css/bootstrap.4.3.1.min.css">
        <link rel="stylesheet"
              href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <script src="https://kit.fontawesome.com/be7d5ac8d8.js" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="/css/group.css">
        <link rel="apple-touch-icon" sizes="180x180" href="/img/fav/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/img/fav/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/img/fav/favicon-16x16.png">
        <link rel="manifest" href="/site.webmanifest">  
    </head>
    <body>
        <div class="container">
            <!-- This is a bit nasty, but it basically says be a column first, and on larger screens be a spaced out row -->
            <div class="sticky-top header d-flex 
                        flex-column
                        flex-md-row justify-content-md-between">
                <a href="/" class="">
                    <img src="/img/AIIM-Logo.svg"
                         srcset="/img/AIIM-Logo.svg 2x"
                         alt="AIIM - Artificial Intelligence and Information Mining research group." id="logo">
                </a>
                <ul class="nav nav-pills justify-content-center">

                    
                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/">
                                Home
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/news.html">
                                News
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/people.html">
                                People
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/research.html">
                                Research
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link active"
                               href="/events.html">
                                Events
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/code.html">
                                Resources
                            </a>
                        </li>

                    

                        

                        
                        
                        
                        
                        

                        <li class="nav-item">
                            <a class="nav-link "
                               href="/publications.html">
                                Publications
                            </a>
                        </li>

                    

                </ul>
            </div>

            
                
                <a href="https://aaai.org/aaai-conference/" class="">
                
                <img src="/events/imgs/AAAI2024_banner.png"
                     alt="Graphs Counterfactual Explainability: A Comprehensive Landscape(AAAI 2024)"
                     style="max-width: 400px"
                     class="img-fluid mx-auto d-block mb-4"/>
                
                </a>
                
            

            
                <h2 class="pt-3">Graphs Counterfactual Explainability: A Comprehensive Landscape(AAAI 2024)</h2>
            
            
                <h3 class="pt-3">Tutorial at the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24) on February 20 and 21, 2024</h3>
            

            <br>
<h3> Organisers </h3>
<section class="people project-people">
    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://scholar.google.es/citations?hl=en&amp;user=NPie5kEAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Mario A. Prado-Romero"
             title="Mario A. Prado-Romero"
             src="/img/people/mprado.jpeg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://scholar.google.es/citations?hl=en&amp;user=NPie5kEAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"> Mario A. Prado-Romero </a>
     </h6>
            
                <div class="bio">Gran Sasso Science Institute</div>
            
        </div>
    </div>


    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://scholar.google.com/citations?user=JIidltYAAAAJ&amp;hl=en&amp;oi=ao"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Dr. Bardh Prenkaj"
             title="Dr. Bardh Prenkaj"
             src="/img/people/prenkaj.jpeg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://scholar.google.com/citations?user=JIidltYAAAAJ&amp;hl=en&amp;oi=ao"> Dr. Bardh Prenkaj </a>
     </h6>
            
                <div class="bio">Sapienza University of Rome</div>
            
        </div>
    </div>


    
        
        







    <div class="person person-with-image row align-items-center">
        <div class="col-auto">
            







    <a href="https://scholar.google.com/citations?user=uTyaicMAAAAJ&amp;hl=en&amp;oi=ao"
       style="text-decoration: none">
        
        <img class="rounded-circle profile"
             alt="Prof. Giovanni Stilo"
             title="Prof. Giovanni Stilo"
             src="/img/people/Stilo.jpeg" />
    
    </a>


        </div>
        <div class="col pl-0">
            <h6 class="person-name"> 
        <a target="_blank" href="https://scholar.google.com/citations?user=uTyaicMAAAAJ&amp;hl=en&amp;oi=ao"> Prof. Giovanni Stilo </a>
     </h6>
            
                <div class="bio">University of L'Aquila</div>
            
        </div>
    </div>


    
</section>
<h3 class="pt-3">Table of contents</h3>
<ul>
  <li><a href="#Abstract">Abstract</a></li>
  <li><a href="#Duration">Duration</a></li>
  <li><a href="#Scope">Scope of the tutorial</a></li>
  <li><a href="#Prerequisites">Prerequisites</a></li>
  <li><a href="#Outline">Outline and Contents</a></li>
  <li><a href="#Bibliography">Bibliography</a></li>
</ul>

<h3 class="pt-3" id="Abstract">Abstract</h3>
<p>Graph Neural Networks (GNNs) have proven highly effective in graph-related tasks, including Traffic Modeling, Learning Physical Simulations, Protein Modeling, and Large-scale Recommender Systems. The focus has shifted towards models that deliver accurate results and provide understandable and actionable insights into their predictions.
Counterfactual explanations have emerged as crucial tools to meet these challenges and empower users. 
For the reasons mentioned above, in this tutorial, we furnish the essential theoretical underpinnings for generating counterfactual explanations for GNNs, arming the audience with the resources to gain a deeper understanding of the outcomes produced by their systems and enabling users to interpret predictions effectively.
First, we present an insight into GNNs, their underlying message-passing architecture, and the challenges of providing post-hoc explanations for their predictions across different domains.
Then, we provide a formal definition of Graph Counterfactual Explainability (GCE) and its potential to provide recourse to users.
Furthermore, we propose a taxonomy of existing GCE methods and give insights into every approach’s main idea, advantages, and limitations.
Finally, we introduce the most frequently used benchmarking datasets, evaluation metrics, and protocols to analyze the future challenges in the field.
<br /></p>

<h3 class="pt-3" id="Duration">Duration</h3>
<p>The tutorial will be carried on for a quarter-day, spanning 1 hour 45 minutes, as the most suitable format to introduce attendees to counterfactual explanations on graphs and their foundational concepts. This duration strikes a balance between providing a comprehensive understanding of the topic without overwhelming participants with unnecessary technical details that may be less relevant to those with limited technical backgrounds. To complement this tutorial, we offer an additional lab session on the same topic to satisfy those interested in diving into the technical aspects of Graph Counterfactual Explanations.
<br /></p>

<h3 class="pt-3" id="Scope">Scope of the tutorial</h3>
<p>The AAAI community has exhibited considerable interest in Graph Neural Networks and Explainable AI, as evidenced by the tutorials in previous editions. Graph Counterfactual Explainability (GCE) holds the potential to captivate a significantly broad audience of researchers and practitioners due to the pervasive nature of graphs and the inherent capacity of GCE methods to provide profound insights into intricate non-linear prediction systems. 
Based on the recently published survey [<a href="#prado2022survey">1</a>], this tutorial will cover fundamental concepts related to Graph Neural Networks, Post-Hoc Explanation methods, and Counterfactual Explanations.
Furthermore, the audience will be provided with a detailed classification of existing GCE methods, an in-depth analysis of their action mechanisms, a qualitative comparison, and a benchmark of their performance on synthetic and real datasets, including brain networks and molecular structures.</p>

<p>The tutorial is aimed at practitioners in academia and industry interested in applying machine learning techniques to analyze graph data. Participants with a background in data mining will gain an understanding of the information provided by explanation methods to end users. Those with machine learning (ML) expertise will delve deeper into state-of-the-art counterfactual explainers, critically analyzing their strengths and weaknesses.
<br /></p>

<h3 class="pt-3" id="Prerequisites">Prerequisites</h3>
<p>The tutorial is aimed at practitioners in academia and industry interested in applying machine learning techniques to analyze graph data. 
Familiarity with basic ML concepts will be beneficial for thoroughly understanding the tutorial.
<br /></p>

<h3 class="pt-3" id="Outline">Outline and Contents</h3>
<p>Counterfactual explanations shed light on the decision-making mechanisms and provide alternative scenarios that yield different outcomes, offering end users recourse—these distinctive characteristics position counterfactual explainability as a highly effective method in graph-based contexts. 
We adopt a multifaceted approach, organizing and examining GCE from different perspectives, such as method taxonomy, classification along various dimensions, detailed descriptions of individual works (including their evaluation processes), discussions on evaluation measures, and commonly used benchmark datasets.
We provide a brief outline of the tutorial in Figure 1. Here, we comprehensively review counterfactual explainability in graphs and their importance with other (factual) explainability methods.</p>

<div class="notes">
  <ul>
    <li><strong>Part I: Introduction and Background (20 mins)</strong></li>
    <ul>
      <li>Wide-spread adoption of GNNs in graph prediction problems</li>
      <li>How do GNNs work?</li>
      <li>Applications of different types of GNNs</li>
    </ul>
    <li><strong>Part II: XAI on Graphs (30 mins)</strong></li>
    <ul>
      <li>Issues of black-box models and the importance of interpretability</li>
      <li>What is a factual explanation?</li>
      <li>(Briefly) Revisiting GNNExplaner and GraphLIME</li>
    </ul>
    <li><strong>Part III: Counterfactual Explainations in Graphs (55 mins)</strong></li>
    <ul>
      <li>What is a graph counterfactual explanation (GCE)?</li>
      <li>GCE taxonomy description and method classification</li>
      <ul>
        <li>Instance-level explainers</li>
        <ul>
          <li>Search-based</li>
          <li>Heuristic-based</li>
          <li>Learning-based</li>
        </ul>
        <li>Model-level explainers</li>
      </ul>
      <li>Benchmarking datasets and evaluation metrics (pro et contra)</li>
    </ul>
  </ul>  
</div>
<p align="center"><strong>Figure 1: The brief outline of the proposed tutorial with its time scheduling.</strong></p>

<p>During the first part of the tutorial, we introduce GNNs [<a href="#scarselli2008graph">2</a>] and their underlying message-passing mechanism to solve graph prediction problems. We will delve into the different types of GNNs and their application in real-world problems [<a href="#wu2020comprehensive">3</a>], such as protein-protein interaction, drug-target affinity prediction, and anomaly detection in social networks.</p>

<p>In the second part, we provide the reader with the challenges of deploying black-box models in critical scenarios and how post-hoc interpretability helps uncover <em>“what is happening under the hood”</em>. Here, we introduce factual explanations [<a href="#yuan2022explainability">4</a>] and briefly revisit the most interesting methods in this category, namely GNNExplainer [<a href="#ying2019gnnexplainer">5</a>], and GraphLIME [<a href="#huang2022graphlime">6</a>].</p>

<p>In the third part, we formalise the definition of Graph Counterfactual Explanation (GCE). We present a taxonomy of the most important references [<a href="#prado2022survey">1</a>], categorised as in Table 1, including search-based explainers [<a href="#liu2021multi">7</a>] , heuristic-based ones 
[<a href="#abrate2021counterfactual">8</a>,<a href="#bajaj2021robust">9</a>,<a href="#wellawatte2022model">10</a>], learning-based ones [<a href="#bajaj2021robust">9</a>,<a href="#cai2022probability">11</a>,<a href="#lucic2022cf">12</a>,<a href="#ma2022clear">13</a>,<a href="#nguyen2022explaining">14</a>,<a href="#numeroso2021meg">15</a>,<a href="#sun2021preserve">16</a>,<a href="#tan2022learning">17</a>,<a href="#wu2021counterfactual">18</a>], and global-level explanation methods [<a href="#huang2023global">19</a>]. Additionally, we list the most common benchmarking datasets and a set of evaluation metrics [<a href="#yuan2022explainability">4</a>,<a href="#guidotti2022counterfactual">20</a>] necessary to assess the (dis)advantages of each counterfactual explainer in the literature. Furthermore, we submitted a lab session proposal that complements this tutorial by providing a hands-on experience.</p>

<figure>
  <p align="center">
    <a href="https://doi.org/10.1145/3618105">
     <img style="width:  100%;" src="/events/imgs/gce_tutorial_references.png" alt="The most important references that will be covered in the tutorial." /></a>
     <figcaption>  
          <p align="center"><strong>Table 1: The most important references that will be covered in the tutorial.</strong></p>  
     </figcaption> 
     </p>
 </figure>
<p><br /></p>

<h3 class="pt-3" id="Bibliography">Bibliography</h3>
<p><a id="prado2022survey">[1]</a> 
Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo, and Fosca Giannotti. 
<em>A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation, and Research Challenges.</em>
ACM Comput. Surv. (September 2023). <a href="https://doi.org/10.1145/3618105">https://doi.org/10.1145/3618105</a></p>

<p><a id="scarselli2008graph">[2]</a> 
F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner and G. Monfardini, <em>The Graph Neural Network Model</em>, in IEEE Transactions on Neural Networks, vol. 20, no. 1, pp. 61-80, Jan. 2009, <a href="https://doi.org/10.1109/TNN.2008.2005605">https://doi.org/10.1109/TNN.2008.2005605</a></p>

<p><a id="wu2020comprehensive">[3]</a> 
Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang and P. S. Yu, <em>A Comprehensive Survey on Graph Neural Networks</em>, in IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 1, pp. 4-24, Jan. 2021, <a href="https://doi.org/10.1109/TNNLS.2020.2978386">https://doi.org/10.1109/TNNLS.2020.2978386</a></p>

<p><a id="yuan2022explainability">[4]</a> 
H. Yuan, H. Yu, S. Gui and S. Ji, <em>Explainability in Graph Neural Networks: A Taxonomic Survey</em>, in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 5, pp. 5782-5799, 1 May 2023, <a href="https://doi.org/10.1109/TPAMI.2022.3204236">https://doi.org/10.1109/TPAMI.2022.3204236</a></p>

<p><a id="ying2019gnnexplainer">[5]</a> 
Ying, Z., Bourgeois, D., You, J., Zitnik, M., and Leskovec,J., 2019. <em>Gnnexplainer: Generating explanations for graph
neural networks</em>. Advances in neural information processing systems, 32.</p>

<p><a id="huang2022graphlime">[6]</a> 
Q. Huang, M. Yamada, Y. Tian, D. Singh and Y. Chang, <em>GraphLIME: Local Interpretable Model Explanations for Graph Neural Networks</em>, in IEEE Transactions on Knowledge and Data Engineering, vol. 35, no. 7, pp. 6968-6972, 1 July 2023, <a href="https://doi.org/10.1109/TKDE.2022.3187455">https://doi.org/10.1109/TKDE.2022.3187455</a></p>

<p><a id="liu2021multi">[7]</a> 
Y. Liu, C. Chen, Y. Liu, X. Zhang and S. Xie, <em>Multi-objective Explanations of GNN Predictions</em>, 2021 IEEE International Conference on Data Mining (ICDM), Auckland, New Zealand, 2021, pp. 409-418, <a href="https://doi.org/10.1109/ICDM51629.2021.00052">https://doi.org/10.1109/ICDM51629.2021.00052</a></p>

<p><a id="abrate2021counterfactual">[8]</a> 
Carlo Abrate and Francesco Bonchi. 2021. <em>Counterfactual Graphs for Explainable Classification of Brain Networks</em>. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD ‘21). Association for Computing Machinery, New York, NY, USA, 2495–2504. <a href="https://doi.org/10.1145/3447548.3467154">https://doi.org/10.1145/3447548.3467154</a></p>

<p><a id="bajaj2021robust">[9]</a> 
Bajaj, M., Chu, L., Xue, Z., Pei, J., Wang, L., Lam, P.,and Zhang, Y. <em>Robust counterfactual explanations on graph neural networks</em>. Advances in neural information processing systems, 34.</p>

<p><a id="wellawatte2022model">[10]</a> 
Wellawatte GP, Seshadri A, White AD. <em>Model agnostic generation of counterfactual explanations for molecules</em>. Chem Sci. 2022 Feb 16;13(13):3697-3705. <a href="https://doi.org/10.1039/d1sc05259d">https://doi.org/10.1039/d1sc05259d</a></p>

<p><a id="cai2022probability">[11]</a> 
Cai, R., Zhu, Y., Chen, X., Fang, Y., Wu, M., Qiao,J., and Hao, Z. 2022. <em>On the Probability of Necessity and Sufficiency of Explaining Graph Neural Networks: A Lower Bound Optimization Approach</em>. arXiv preprint arXiv:2212.07056</p>

<p><a id="lucic2022cf">[12]</a> 
Ana Lucic, Maartje A. Ter Hoeve, Gabriele Tolomei, Maarten De Rijke, Fabrizio Silvestri, <em>CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks</em>, in  Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, PMLR 151:4499-4511, 2022.</p>

<p><a id="ma2022clear">[13]</a> 
Ma, J.; Guo, R.; Mishra, S.; Zhang, A.; and Li, J., 2022. <em>CLEAR: Generative Counterfactual Explanations on Graphs</em>. Advances in neural information processing systems, 35, 25895–25907.</p>

<p><a id="nguyen2022explaining">[14]</a> 
T. M. Nguyen, T. P. Quinn, T. Nguyen and T. Tran, <em>Explaining Black Box Drug Target Prediction Through Model Agnostic Counterfactual Samples</em>, in IEEE/ACM Transactions on Computational Biology and Bioinformatics, vol. 20, no. 2, pp. 1020-1029, 1 March-April 2023, <a href="https://doi.org/10.1109/TCBB.2022.3190266">https://doi.org/10.1109/TCBB.2022.3190266</a></p>

<p><a id="numeroso2021meg">[15]</a> 
Numeroso, Danilo and Bacciu, Davide, <em>MEG: Generating Molecular Counterfactual Explanations for Deep Graph Networks</em>, 2021 International Joint Conference on Neural Networks (IJCNN). <a href="https://doi.org/10.1109/IJCNN52387.2021.9534266">https://doi.org/10.1109/IJCNN52387.2021.9534266</a></p>

<p><a id="sun2021preserve">[16]</a> 
Sun, Y., Valente, A., Liu, S., &amp; Wang, D. (2021). Preserve, Promote, or Attack? GNN Explanation via Topology Perturbation. ArXiv. <a href="https://arxiv.org/abs/2103.13944">https://arxiv.org/abs/2103.13944</a></p>

<p><a id="tan2022learning">[17]</a> 
Juntao Tan, Shijie Geng, Zuohui Fu, Yingqiang Ge, Shuyuan Xu, Yunqi Li, and Yongfeng Zhang. 2022. <em>Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning</em>. In Proceedings of the ACM Web Conference 2022 (WWW ‘22).<a href="https://doi.org/10.1145/3485447.3511948">https://doi.org/10.1145/3485447.3511948</a></p>

<p><a id="wu2021counterfactual">[18]</a> 
Wu, H.; Chen, W.; Xu, S.; and Xu, B. 2021. <em>Counterfactual Supporting Facts Extraction for Explainable Medical Record Based Diagnosis with Graph Network</em>. In Proc. of
the 2021 Conf. of the North American Chapter of the Assoc. for Comp. Linguistics: Human Lang. Techs., 1942–1955. <a href="https://aclanthology.org/2021.naacl-main.156/">https://aclanthology.org/2021.naacl-main.156/</a></p>

<p><a id="huang2023global">[19]</a>
Zexi Huang, Mert Kosan, Sourav Medya, Sayan Ranu, and Ambuj Singh. 2023. <em>Global Counterfactual Explainer for Graph Neural Networks</em>. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (WSDM ‘23). Association for Computing Machinery, New York, NY, USA, 141–149. <a href="https://doi.org/10.1145/3539597.3570376">https://doi.org/10.1145/3539597.3570376</a></p>

<p><a id="guidotti2022counterfactual">[20]</a> 
Guidotti, R. <em>Counterfactual explanations and how to find them: literature review and benchmarking</em>. Data Min Knowl Disc (2022). <a href="https://doi.org/10.1007/s10618-022-00831-6">https://doi.org/10.1007/s10618-022-00831-6</a></p>

<p><br /></p>




            <div class="footer">
                <p>
                    © Copyright 2019-2023 - Artificial Intelligence and Information Mining research group - All rights reserved.
                </p>
            </div>

        </div> <!-- /container -->

        <!-- Support retina images. -->
        <script type="text/javascript"
                src="/js/srcset-polyfill.js"></script>
        <!-- Global site tag (gtag.js) - Google Analytics -->
	    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-160388153-1"></script>
	    <script>
	        window.dataLayer = window.dataLayer || [];
	        function gtag(){dataLayer.push(arguments);}
	        gtag('js', new Date());

	        gtag('config', 'UA-160388153-1');
	    </script>
    </body>
</html>
